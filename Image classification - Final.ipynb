{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import hashlib\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.istockphoto.com/search/2/image?mediatype=photography&page=3&phrase=cruise%20ship&sort=best\"\n",
    "# headers = {\n",
    "#     'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "#     'Accept-Language': 'en-US,en;q=0.8',\n",
    "#     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36',\n",
    "#     'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "#     'Referer': 'http://www.wikipedia.org/',\n",
    "#     'Connection': 'keep-alive',\n",
    "# }\n",
    "\n",
    "# get_url = requests.get(url=url,headers=headers).text\n",
    "# # print(get_url)\n",
    "\n",
    "# soup = BeautifulSoup(get_url,'lxml')\n",
    "\n",
    "# images = []\n",
    "\n",
    "# img_links = soup.select('img[src^=\"https://media.istockphoto.com/photos\"]')\n",
    "# # print(img_links)\n",
    "\n",
    "# for i in range(len(img_links)):\n",
    "#     images.append(img_links[i]['src'])\n",
    "\n",
    "# for i in range(len(images)):\n",
    "#     ships = \"D:/mixed images/ships/\"+str(i)+\".jpg\"\n",
    "#     urllib.request.urlretrieve(images[i],ships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('D:/mixed images')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashlist=[]\n",
    "# unique = dict()\n",
    "# for img in data_dir.glob('*/*.jpg'):\n",
    "#     filehash = hashlib.md5(open(img,\"rb\").read()).hexdigest()\n",
    "#     hashlist.append(filehash)\n",
    "\n",
    "    \n",
    "#     if filehash in unique:\n",
    "#         os.remove(img)\n",
    "#     else:\n",
    "#         unique[filehash] = data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data_dir.glob('*/*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planes = list(data_dir.glob('airplanes/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.open(planes[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = [list(data_dir.glob('airplanes/*')),\n",
    "            list(data_dir.glob('animals/*')),\n",
    "            list(data_dir.glob('birds/*')),\n",
    "            list(data_dir.glob('cars/*')),\n",
    "            list(data_dir.glob('flowers/*')),\n",
    "            list(data_dir.glob('people/*')),\n",
    "            list(data_dir.glob('ships/*')),\n",
    "            list(data_dir.glob('traffic_signs/*')),\n",
    "            list(data_dir.glob('trains/*'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_list = os.listdir(data_dir)\n",
    "\n",
    "obj_img_dict = dict(zip(obj_list,img_list))\n",
    "\n",
    "obj_label_dict = dict(zip(obj_list,[0,1,2,3,4,5,6,7,8]))\n",
    "obj_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for image_name,images in obj_img_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img,(299,299))\n",
    "        X.append(resized_img)\n",
    "        y.append(obj_label_dict[image_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.35,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train/255\n",
    "X_test_scaled = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_classes = 9\n",
    "model = keras.Sequential()\n",
    "\n",
    "# building the convolution layers\n",
    "model.add(keras.layers.Conv2D(32,(3,3),input_shape= (299,299,3),padding='same',activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(32,(3,3), padding='same',activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "# model.add(keras.layers.Conv2D(128,(3,3), padding='same',activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Flatten())\n",
    "    \n",
    "# building the dense layers\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5)) # optional\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(obj_classes,activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, batch_size=64,epochs=40, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "tar_file = tarfile.open(\"D:\\imagenet_inception_v3_feature_vector_5.tar.gz\")\n",
    "tar_file.extractall('D:\\inception_v3')\n",
    "tar_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features = keras.models.load_model('D:\\inception_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model_vectors = hub.KerasLayer(get_features,input_shape=(299,299,3),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_classes = 9\n",
    "inceptionv3_model = keras.Sequential()\n",
    "inceptionv3_model.add(inception_model_vectors)\n",
    "inceptionv3_model.add(keras.layers.Dense(obj_classes,activation='softmax'))\n",
    "\n",
    "inceptionv3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionv3_model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "inceptionv3_model.fit(X_train_scaled, y_train, batch_size=32,epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionv3_model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
